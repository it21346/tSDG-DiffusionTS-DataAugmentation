
The need for high quality data and privacy of said data, has introduced the idea for artificially generating data **(Synthetic Data)**. Although it sounds as a good idea, at the same time the data must be generated properly and follow the underlying distribution of the original training data.

**SMOTE (Synthetic Minority Oversampling Technique)** is one of the oldest algorithms that try to replicate a data distribution. Along with **Random OverSampling (ROS)** and other traditional algorithms, the emergence of deep learning has quite changed the landscape of how to tackle this task. More specifically, the emergence of **Varational AutoEncoders (VAEs)** and **Generative adversarial networks (GANs)**.

GANs are generally used in the context of images, computer vision tasks. Nonetheless, the generation of synthetic tabular data is of great interest as well.

Under the hood, the GAN consists of two models, a generator model G (**Generator**) and a discriminator model D (**Discriminator**). The Generator tries to generate samples that follow the underlying distribution of the data. On the other hand, the Discriminator receives an observation, either from the original dataset or synthesized by the generator, classifies it as fake or real. Typically the models G and D are neural networks, thus also called networks. Noteworthy is that these two networks are trained seperately.

The training of the Discriminator consists of samples from the original dataset and synthetic samples generated by the Generator. The Discriminator outputs a propability (continuous number ranging from 0 to 1) that indicates whether an observation originates from the original data (0 means that the Discriminator is 100% sure that the given example was synthesized), while 1 means the exact opposite (the Discriminator is 100% sure that the given example was from the original dataset).

The training of the Generator consists of input as random noise (**latent space**), commonly from a multivariate normal distribution. As for the output, it is a data point with the same features of the original dataset. However, there is no dataset to inform whether a particular point in the latent space is mapped by G into a reasonable and useful example. Thus, the generator is only provided with a value from the loss function. Typically that loss function is the BCE (Binary cross-entropy) between the Discriminator's output and a response vector of 1's (**Note**: Ideally the samples generated by the Generator should be classified by the Discriminator as real images and thus, the synthesized instances from G are marked as coming from the original data (1) ).

As the training progresses, G will become more realistic and D will also improve at determining whether a sample is real or synthetic. Ideally, G will be able to mimic the real data distribution and D's distinguishing propability will be as good as a random guess (50%).

Some **drawbacks** of GANs (Vanilla GANs) is **Oscillatory loss (instability)**, which is a common problem during training. Another problem is the lack of information it usually provides (uninformative loss). Another fairly common phenomenon is that the Generator can find a small number of samples that can fool the Discriminator, which is called **Mode Collapse**. If it finds these specific samples, it will focus on these to minimize its loss function. Another issue is that GANs require a good amount of hyperparameter tuning. Finally, there is the vanishing gradient problem, which could happen if the discriminator is close optimal and allows it to accurately discern generated samples from real ones and causes the Generator's training to fail. 



# Different variations of GANs through the years (chronologically)

- **Conditional Generative Adversarial Network (CGAN)** : By passing the labels as well on the G,D, one can make explicit generations of a particular class.
- **Deep Convolutional Generative Adversarial Network (DCGAN)** : Uses Convolutional layers.
- **Information Maximizing Generative Adversarial Network (InfoGAN)** : It attempts to learn disentangled information. Meaning to give semantic meaning to features in the latent space. InfoGAN can successfully recognize writing styles from handwritten digits in the MNIST dataset, detect hairstyles or eyeglasses in the CelebA dataset, or even background digits from the central digit in the SVHN dataset.
- **Auxiliary Classifier Generative Adversarial Network (AC-GAN)** : It makes the Generator class dependent and adds an auxiliary model to the discriminator whose purpose is to reconstruct the class label.
- **Stacked Generative Adversarial Network (StackGAN)** : It can generate images from text descriptions.
- **Wasserstein Generative Adversarial Networks (WGAN)** : It changed the training phase, such that the Discriminator is updated more often than the Generator at each iteration, and this process avoids mode collapse and provides meaningful loss metrics.
- **Cycle-Consistent Generative Adversarial Network (CycleGAN)** : It is used for image-to-image translation without paired data. It translates an image from a domain X to a domain. One main difference is that it consists of two Generators and two Discriminators.
- **Multi-track sequential GAN (MuseGAN)** : GAN for music generation.
- **Progressive growing of Generative Adversarial Networks (ProGAN)** : It helps stabilize GAN training by progressively increasing the resolution of generated images. In the beggining the Generator and Discriminator produce images with few pixels. Then, layers corresponding to higher resolutions are added in the training process, allowing the creation of high-quality images.
- **Self-Attention Generative Adversarial Networks (SAGAN)** : Maintains long-range relationships within an image rather than just local points. By using spectral normalization, they improved the training dynamics of the Generator. In addition, the Discriminator can assess whether highly detailed features in distant image regions match each other.
- **Big Generative Adversarial Network (BigGAN)** : It upscales existing GAN models and produces high-quality images. It also introduced techniques that detect training instability if one is to train GANs at a large scale.
- **Style-based Generative Adversarial Networks (StyleGAN)** : This new architecture is able to learn to separate high-level features and stochastic variation. In fact, the new generator improves the quality metrics over the state-of-the-art, untangles the latent variables better, and has better interpolation properties.
- **GauGAN** : Allows users to sketch an abstract scene and then turn it into a detailed image.
- **Pluralistic Image Inpainting GAN (PiiGAN)** : This model attempts to fill in large missing areas in an image.
- **Multi-StyleGAN** : It is a novel GAN architecture used to study the dynamic processes of life at the level of single cells. Since acquiring images to study such processes is costly and complex, the Multi-StyleGAN is a descriptive approach that simulates microscopic images of living cells.

The aforementioned variations of GANs have been mainly used for image generation tasks. However, many datasets have a tabular format and the most popular GAN architectures cannot be used in such a setting because tabular data has unique properties. Thus, following are three GAN architectures specifically for tabular data.

- **TGAN** : Given a dataset D, which is already split into D_train and D_test, the aim of the proposed model is twofold. Given a machine learning model, its accuracy on D_test when trained on D_train should be similar to its accuracy on D_test, but this time when trained using D_synth, which is the synthetic data. To achieve these goals, we need to transform the data. A GAN usually consists of two neural networks, so we need to properly represent the data before feeding it as input. This problem is addressed by applying mode-specific normalization for numerical variables and smoothing for categorical variables. Regarding the mode-specific normalization, it is used to handle non-Gaussian and multimodal distributions, by fitting a **Gaussian mixture model (GMM)**, which models a distribution as a weighted sum of Gaussian distributions to each numerical variable and calculates the probability that a sample from a numerical column comes from each of the Gaussian distributions. These probabilities are then used to encode the values of the rows corresponding to the numerical features. Regarding the smoothing of the categorical variables, this is achieved by representing them as one-hot-encoded vectors, adding noise to each dimension and renormalizing the vector. After these operations, the data is ready to be fed to the TGAN. The generator is a LSTM network that generates the numeric variables in two steps and the categorical variables in one step. The discriminator is a fully connected neural network.
- **CTGAN** : CTGAN is an improvement of TGAN in the sense of not just preserving the correlation between any pair of columns in the synthetic data, but it also aims to preserve the joint distribution of all columns. Regarding input data transformation, instead of a *Gaussian mixture model (GMM)*, a **variational Gaussian mixture (VGM)** model is used for the **numerical columns**. **Continuous values** are represented as a one-hot vector indicating the mode and a scalar indicating the value within the mode. The **Categorical features** are only one-hot-encoded without adding noise. Three key techniques introduced in this model are mode-specific normalization, training by sampling, and the conditional generator.
- **TabFairGAN** : This model is a *WGAN* with a gradient penalty. It uses, as the others, one-hot-encoding to represent the categorical features. For the numerical features, a quantile transformation was used and specifically for a **cumulative distribution function (CDF)**. Regarding the architecture, an initial fully connected layer (with ReLU activation) constitutes the generator, followed by a second layer that uses ReLU for numerical attributes and Gumbel softmax for one-hot-encoding of the categorical features. In the last layer, all the attributes are concatenated, producing the final generated data. The critic is constituted by fully connected layers with the LeakyReLU activation function.

# Quick review of the standard methods used for synthetic generation (tabular data)
- **Random Oversampling (ROS)** : It randomly samples from the minority class(es) with replacement.
- **Synthetic Minority Oversampling Technique (SMOTE)** : Given a data point from a minority class and its nearest neighbor from the same class, the distance between them is determined. This distance is multiplied by a random number ([0,1]) and added to the selected data point. This causes the new sample to fall in the line segment between the original sample and its neighbor.
- **Gaussian Mixture Model (GMM)** : It is a probabilistic model that assumes that the data can be modeled by a weighted sum of finite number of Gaussian distributions.
# Quick review of the deep learning methods used for synthetic generation
- **Bayesian Networks** : It is a type of probabilistic graphical model that uses Bayesian inference for probability computations over a directed acyclic graph.
- **Autoencoders (AE)** : It is a special type of feedforward neural network that consists of two parts: an encoder network that learns to compress high-dimensional data into a low-dimensional, latent spacial representation, and a decoder network that decompresses the compressed representation into the original domain.
- **Generative adversarial networks (GANs)** : *(Already explained)*


# Synthetic sample quality evaluation (Tabular data)

There is a huge number of evaluation techniques which some depend on specific types of data or very specific domains. The following will focus on tabular data.

The simplest way to evaluate the quality of synthetic data is to compare their basic statistics (mean, median, standard deviation) with those of the real data. However, this can be misleading as showed by a famous statistician. Some datasets could have nearly identical basic descriptive statistics, but their distributions could be very different. Another approach is plotting the data by using graphical representations (bpx plots, histograms, violin plots).

One can compare the graphs of the real data with those of the synthetic data along with descriptive statistics. The Q-Q plot is a probability plot that can compare between two data distributions and evaluate their similarity.

Moreover, Machine learning efficacy is another technique for evaluating synthetic data. It consists of, given a dataset, D, already split into a trainset, D_train, and testset, D_test, comparing the performance of ML models (e.g., logistic regression, decision trees, artificial neural networks) when trained in D_train, and on D_synth (the synthetic data), and evaluated in D_test. If the performance (in terms of accuracy, recall, precision, F1-score) of the models trained using D_train and using D_synth are similar, then the synthetic data is likely to follow the underlying data distribution.

Some more generally evaluation techniques (not specifically for tabular data) are namely the **Inception Score** and the **Frechet Inception Distance**. These are mainly used for image-generated data.

**GAN-train** and **GAN-test** are two metrics that despite having "GAN" in their name, the synthetic samples do not need to be generated exclusively with a GAN  and also can be applied to other types of data, not only images. 
  - GAN-train : A classification network is trained with instances generated by a synthetic data generation method and its performance is evaluated against a test set consisting of real-world data. This measure provides a measure of how apart the generated and true distributions are.
  - GAN-test : A classification network is trained on a real dataset and evaluated on the generated data. GAN-test provides a measure to evaluate whether the synthetic data generation method has overfitted or underfitted the data.

A domain and model-independent evaluation metric has been introduced. This metric is three-dimensional (α-Precision, β-Recall, Authenticity) and it evaluates the fidelity, diversity and generalization of each generative model and is independent of the domain. Moreover, the three components correspond to interpretable probabilistic quantities, making it easier to detect a lack of synthetic data quality.
  - **Fidelity** : The α-Precision component measures the similarity between the generated and the real samples.
  - **Diversity** : The β-Recall component evaluates how diverse the generated samples are. That is, whether the generated data is diverse enough to cover the existing variability in the real data.
  - **Generalization** : The Authenticity component is a measure of how well the model can generalize and not overfit the real data.

The first two components are computed by embedding the real and synthetic data in hyperspheres. The original data and the generated data are mapped from the original domain to a hypersphere of radius r. The third component is computed by evaluating the proximity of the real data to the generated data in the embedding space using a hypothesis test. This metric also has the ability to evaluate each instance and therefore have a "curated" version of the generated dataset consisting only of high-quality samples. 


