{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Concatenate, \\\n",
    "                                    LSTM, Activation, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow_addons.layers import SpectralNormalization as SN\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "file_name = 'attack_regressor'\n",
    "dir_name = file_name + '_dir'\n",
    "weights_dir = 'forecast_dir/ckpt'\n",
    "os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('../../data/processed/normalized_generated_data.npz')\n",
    "gen_electrical_data = data['electrical_data']\n",
    "gen_labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../../../data/processed/full_data.npz')\n",
    "real_electrical_data = data['electrical_data'][:500]\n",
    "real_labels = data['labels'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.load('../../../../data/processed/labeled_data.npz')['electrical_values']\n",
    "difs = np.max(signal, axis=1) - np.min(signal, axis=1)\n",
    "miu = np.mean(difs)\n",
    "sigma = np.std(difs)\n",
    "print('miu =', miu)\n",
    "print('sigma =', sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels):\n",
    "    train_factor, val_factor = 0.8, 0.1\n",
    "    train_limit, val_limit = int(len(data) * train_factor), int(len(data) * (train_factor + val_factor))\n",
    "    train_data, train_labels = data[:train_limit], labels[:train_limit]\n",
    "    val_data, val_labels = data[train_limit:val_limit], labels[train_limit:val_limit]\n",
    "    test_data, test_labels = data[val_limit:], labels[val_limit:]\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 720 # One month of data\n",
    "nr_labels = 6 # from labels + timestamp\n",
    "emb_input_dim = 28 + gen_electrical_data.shape[1] - data_length + 1 # Added values are for timestamp\n",
    "emb_output_dim = 32\n",
    "nr_samples = 500\n",
    "batch_size = nr_samples\n",
    "untargeted_vals = {}\n",
    "targeted_max_vals = {}\n",
    "targeted_min_vals = {}\n",
    "interval = np.linspace(0.01, 0.1, 10)\n",
    "plot_interval = np.linspace(0, 0.1, 11)\n",
    "attack_names = ['FGSM', 'BIM', 'PGD']\n",
    "sample_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(kernel_size, filters, padding, input_layer):\n",
    "    sn_conv_1d = SN(Conv1D(kernel_size=kernel_size, filters=filters, padding=padding))(input_layer)\n",
    "    bn = BatchNormalization()(sn_conv_1d)\n",
    "    act = Activation('relu')(bn)\n",
    "    mp_1d = MaxPooling1D()(act)\n",
    "    res = Dropout(0.2)(mp_1d)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    sampled_data = Input((data_length, gen_electrical_data.shape[2]), name='input_1')\n",
    "    sampled_labels = Input((nr_labels,), name='input_2')\n",
    "    label_embedding = SN(Embedding(emb_input_dim, emb_output_dim, input_length=nr_labels))(sampled_labels)\n",
    "    flatten_embedding = Flatten()(label_embedding)\n",
    "    dense_embedding = SN(Dense(64))(flatten_embedding)\n",
    "    conv1 = conv_block((3), 128, 'same', sampled_data)\n",
    "    conv2 = conv_block((5), 128, 'same', sampled_data)\n",
    "    conv3 = conv_block((7), 128, 'same', sampled_data)\n",
    "    conc_convs = Concatenate(axis=-1)([conv1, conv2, conv3])\n",
    "    lstm1 = LSTM(128, return_sequences=True)(conc_convs)\n",
    "    bn1 = BatchNormalization()(lstm1)\n",
    "    lstm2 = LSTM(128)(bn1)\n",
    "    bn2 = BatchNormalization()(lstm2)\n",
    "    conc_all = Concatenate(axis=1)([bn2, dense_embedding])\n",
    "    dense_final = SN(Dense(128, activation='relu'))(conc_all)\n",
    "    res = SN(Dense(1, activation='tanh'))(dense_final)\n",
    "    model = Model([sampled_data, sampled_labels], res, name='C-RNN')\n",
    "    model.compile(optimizer = Adam(1e-3, 0.5, 0.9), loss = 'mse', metrics = ['mae', 'mape'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_model = create_model()\n",
    "real_model.load_weights(weights_dir + '/weights.ckpt')\n",
    "gen_model = create_model()\n",
    "gen_model.load_weights(weights_dir + '/gen_weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data, labels, nr_samples=500):\n",
    "    indexes = np.random.randint(0, data.shape[0], nr_samples)\n",
    "    sampled_data = data[indexes]\n",
    "    hours = np.random.randint(0, data.shape[1] - data_length, nr_samples)\n",
    "    X = np.array([x[h:h + data_length] for x, h in zip(sampled_data, hours)])\n",
    "    l = np.array([np.concatenate((l, h), axis=-1) for l, h in zip(labels[indexes], np.expand_dims(hours, -1))])\n",
    "    y = np.array([x[h + data_length, 0] for x, h in zip(sampled_data, hours)])\n",
    "    return X, l, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(X, l, y, model, eps, targeted, clip_min=-1, clip_max=1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(X)\n",
    "        y_pred = model([X, l])\n",
    "        loss = MSE(y, y_pred)\n",
    "        if targeted:\n",
    "            loss = -loss\n",
    "    grad = tape.gradient(loss, X)\n",
    "    normalized_grad = tf.sign(grad)\n",
    "    normalized_grad = tf.stop_gradient(normalized_grad)\n",
    "    scaled_grad = eps * normalized_grad\n",
    "    X_adv = X + scaled_grad\n",
    "    X_adv = tf.clip_by_value(X_adv, clip_min, clip_max)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(X, l, y, model, eps, targeted, eps_iter=None, max_iter=10, rand_init=True, clip_min=-1, clip_max=1):\n",
    "    if eps_iter == None:\n",
    "        eps_iter = eps / 3\n",
    "    if rand_init:\n",
    "        eta = tf.random.uniform(tf.shape(X), -eps, eps)\n",
    "    else:\n",
    "        eta = tf.zeros_like(X)\n",
    "    eta = tf.clip_by_value(eta, -eps, eps)\n",
    "    X_adv = X + eta\n",
    "    for i in trange(max_iter):\n",
    "        X_adv = FGSM(X_adv, l, y, model, eps_iter, targeted, clip_min, clip_max)\n",
    "        eta = X_adv - X\n",
    "        eta = tf.clip_by_value(eta, -eps, eps)\n",
    "        X_adv = X + eta\n",
    "        X_adv = tf.clip_by_value(X_adv, clip_min, clip_max)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIM(X, l, y, model, eps, targeted, eps_iter=None, max_iter=10, clip_min=-1, clip_max=1):\n",
    "    return PGD(X, l, y, model, eps, targeted, eps_iter, max_iter, False, clip_min, clip_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_targets = tf.ones((nr_samples), name='max_targets')\n",
    "min_targets = -tf.ones((nr_samples), name='min_targets')\n",
    "\n",
    "for electrical_data, labels, model in [(real_electrical_data, real_labels, real_model), \\\n",
    "                                       (gen_electrical_data, gen_labels, gen_model)]:\n",
    "    _, _, _, _, test_data, test_labels = split_data(electrical_data, labels)\n",
    "    X, l, y = generate_data(test_data, test_labels, nr_samples)\n",
    "    X_tf = tf.convert_to_tensor(X, dtype=tf.float32, name='X')\n",
    "    l_tf = tf.convert_to_tensor(l, dtype=tf.int32, name='l')\n",
    "    y_tf = tf.convert_to_tensor(y, dtype=tf.float32, name='y')\n",
    "    print('Original results:')\n",
    "    mse, mae, mape = model.evaluate([X, l], y, batch_size=batch_size)\n",
    "    clean_result = (mse, mae, mape, 0., X[sample_index])\n",
    "    clean_results = np.array([clean_result for _ in plot_interval], dtype=object)\n",
    "    untargeted_vals['Orig'] = clean_results\n",
    "    targeted_max_vals['Orig'] = clean_results\n",
    "    targeted_min_vals['Orig'] = clean_results\n",
    "    for attack_name in attack_names:\n",
    "        print('For', attack_name, 'attack:')\n",
    "        attack_type = eval(attack_name)\n",
    "        for results_dict, targeted, y_tar in [(untargeted_vals, False, y_tf), (targeted_max_vals, True, max_targets), \\\n",
    "                                      (targeted_min_vals, True, min_targets)]:\n",
    "            vals = [clean_result]\n",
    "            for eps in interval:\n",
    "                print('For eps = %.2f:' % eps)\n",
    "                X_adv = attack_type(X_tf, l_tf, y_tar, model, eps, targeted)\n",
    "                mse, mae, mape = model.evaluate([X_adv, l], y_tar, batch_size=batch_size)\n",
    "                perturbation = np.nanmean(np.abs((X_adv - X)))\n",
    "                vals.append((mse, mae, mape, perturbation, X_adv[sample_index]))\n",
    "            results_dict[attack_name] = np.array(vals, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_types = ['No Target', 'Max Target', 'Min Target']\n",
    "colors = ['g', 'b', 'r', 'c']\n",
    "linestyles=['-','-','-.','--']\n",
    "for i, metric in enumerate(['MSE', 'MAE', 'MAPE', 'Perturbation']):\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(30, 10)\n",
    "    fig.suptitle(metric)\n",
    "    for j, results_dict in enumerate([untargeted_vals, targeted_max_vals, targeted_min_vals]):\n",
    "        ax = axs[j]\n",
    "        ax.title.set_text(result_types[j])\n",
    "        ax.set_xlabel('epsilon')\n",
    "        ax.set_ylabel('Values')\n",
    "        for k, attack in enumerate(['Orig'] + attack_names):\n",
    "            ax.plot(plot_interval, results_dict[attack][:, i], color=colors[k], linestyle=linestyles[k], label=attack)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untargeted_vals_2 = {'untargeted_' + key: val for key, val in untargeted_vals.items()}\n",
    "targeted_max_vals_2 = {'targeted_max_' + key: val for key, val in targeted_max_vals.items()}\n",
    "targeted_min_vals_2 = {'targeted_min_' + key: val for key, val in targeted_min_vals.items()}\n",
    "np.savez_compressed(dir_name + '/attack_regressor_metrics.npz', **untargeted_vals_2, **targeted_max_vals_2, **targeted_min_vals_2)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
