{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Conv1D, \\\n",
    "                                    UpSampling1D, Embedding, Multiply, Activation\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow_addons.layers import GELU\n",
    "from scipy.fft import rfft, irfft\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "file_name = 'cDCGAN'\n",
    "dir_name = file_name + '_dir'\n",
    "ckpt_dir = dir_name + '/ckpt'\n",
    "plots_dir = dir_name + '/plots'\n",
    "os.mkdir(dir_name)\n",
    "os.mkdir(ckpt_dir)\n",
    "os.mkdir(plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('../../data/processed/full_data.npz')\n",
    "electrical_data = data['electrical_data']\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrical_data = np.concatenate((electrical_data, electrical_data[:5]), axis=0)\n",
    "labels = np.concatenate((labels, labels[:5]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cDCGANMonitor Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGANMonitor(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            print('\\nSaving the generator at epoch', epoch)\n",
    "            self.model.generator.save_weights(ckpt_dir + '/generator_weights_' + str(epoch) + '.ckpt')\n",
    "            \n",
    "            print('Saving the discriminator at epoch', epoch)\n",
    "            self.model.discriminator.save_weights(ckpt_dir + '/discriminator_weights_' + str(epoch) + '.ckpt')\n",
    "             \n",
    "            print('Plotting generated samples')\n",
    "            self.model.save_plots(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cDCGAN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(Model):\n",
    "    def __init__(self):\n",
    "        super(cDCGAN, self).__init__()\n",
    "        \n",
    "        # Constants and Shapes\n",
    "        self.g_steps = 3\n",
    "        self.nr_labels = 5\n",
    "        self.max_labels = 28\n",
    "        self.noise_length = 144\n",
    "        self.seq_length = 8760\n",
    "        self.nr_features = 6\n",
    "        self.emb_length = 50\n",
    "        self.gen_input_shape = (self.noise_length, self.nr_features)\n",
    "        self.discriminator_input_shape = (self.seq_length, self.nr_features)\n",
    "        \n",
    "        # The Generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.summary()\n",
    "        \n",
    "        # The Discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.summary()\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        #self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    def compile(self):\n",
    "        super(cDCGAN, self).compile()\n",
    "        self.d_optimizer = Adam(2e-4, 0.5, 0.9)\n",
    "        self.g_optimizer = Adam(2e-4, 0.5, 0.9)\n",
    "\n",
    "        \n",
    "    def build_generator(self):\n",
    "        # Hyperparameters\n",
    "        padding = \"valid\"\n",
    "        strides = 2\n",
    "        dropout = 0.2\n",
    "        momentum = 0.8\n",
    "        strides = 2\n",
    "\n",
    "        # Input\n",
    "        noise = Input(shape=(self.noise_length,))\n",
    "        labels = Input(shape=(self.nr_labels,), dtype='int32')\n",
    "        label_embedding = Embedding(self.max_labels, self.emb_length, input_length=self.nr_labels)(labels)\n",
    "        flatten_embedding = Flatten()(label_embedding)\n",
    "        dense_embedding = Dense(self.noise_length)(flatten_embedding)\n",
    "        multiplied_data = Multiply()([noise, dense_embedding])\n",
    "        dense_data = Dense(self.noise_length * self.nr_features)(multiplied_data)\n",
    "        gen_input = Reshape(self.gen_input_shape)(dense_data)\n",
    "        print('\\nInput shape for the Generator =', gen_input.shape)\n",
    "\n",
    "        # Structure\n",
    "        model = Sequential() # 144\n",
    "\n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=12, filters=1024, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 277\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=4, filters=512, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 551\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=5, filters=256, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 1098\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=4, filters=128, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 2193\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=4, filters=64, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 4383\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=5, filters=32, padding=padding))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 8762\n",
    "        \n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(kernel_size=4, filters=32, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout)) # 8761\n",
    "\n",
    "        model.add(UpSampling1D())\n",
    "        model.add(Conv1D(self.nr_features, kernel_size=4, padding=padding, strides=strides))\n",
    "        model.add(Activation(\"tanh\")) # 8760\n",
    "\n",
    "        print('Generator Structure:')\n",
    "        model.build((None, *self.gen_input_shape))\n",
    "        #model.summary()\n",
    "\n",
    "        # Result\n",
    "        res = model(gen_input)\n",
    "        return Model([noise, labels], res, name=\"generator\")\n",
    "    \n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        # Hyperparameters\n",
    "        padding = \"causal\"\n",
    "        dropout = 0.2\n",
    "        momentum = 0.8\n",
    "        strides = 2\n",
    "\n",
    "        # Input\n",
    "        elecs = Input(shape=(self.seq_length, self.nr_features))\n",
    "        labels = Input(shape=(self.nr_labels,), dtype='int32')\n",
    "        \n",
    "        label_embedding = Embedding(self.max_labels, self.seq_length // self.nr_labels, input_length=self.nr_labels)(labels)\n",
    "        flatten_embedding = Flatten()(label_embedding)\n",
    "        reshaped_embedding = Reshape((self.seq_length, 1))(flatten_embedding)\n",
    "\n",
    "        discriminator_input = Multiply()([elecs, reshaped_embedding])\n",
    "        print('\\nInput shape for the Discriminator =', discriminator_input.shape)\n",
    "        \n",
    "        # Structure\n",
    "        model = Sequential() # 8760 * 6\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=32, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=64, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=128, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=256, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=512, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Conv1D(kernel_size=4, filters=1024, padding=padding, strides=strides))\n",
    "        model.add(BatchNormalization(momentum=momentum))\n",
    "        model.add(GELU())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        print('Discriminator Structure:')\n",
    "        model.build((None, *self.discriminator_input_shape))\n",
    "        #model.summary()\n",
    "        \n",
    "        # Result\n",
    "        res = model(discriminator_input)\n",
    "\n",
    "        return Model([elecs, labels], res, name=\"discriminator\")\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        real_samples, labels = data\n",
    "        \n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_samples)[0]\n",
    "        \n",
    "        valid = tf.ones((batch_size, 1), dtype=tf.int32)\n",
    "        fake = tf.zeros((batch_size, 1), dtype=tf.int32)\n",
    "        \n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal([batch_size, self.noise_length])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake data from the latent vector\n",
    "            gen_samples = self.generator([random_latent_vectors, labels], training=True)\n",
    "            # Add noise to gen_samples and real_samples for regularization\n",
    "            to_add = tf.constant([[[1.0, 1.0, 0.0, 0.0, 0.0, 1.0]]]) * 0.02\n",
    "            additional_noise = tf.random.normal((batch_size, self.seq_length, self.nr_features)) * to_add \n",
    "            # Get the logits for the fake data\n",
    "            fake_vals = self.discriminator([gen_samples + additional_noise, labels], training=True)\n",
    "            # Get the logits for the real data\n",
    "            real_vals = self.discriminator([real_samples + additional_noise, labels], training=True)\n",
    "            # Calculate the discriminator loss using the fake and real image logits\n",
    "            d_costs = binary_crossentropy(valid, real_vals) + binary_crossentropy(fake, fake_vals)\n",
    "            d_loss = d_costs * 0.5\n",
    "\n",
    "        # Get the gradients w.r.t the discriminator loss\n",
    "        d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        # Update the weights of the discriminator using the discriminator optimizer\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "\n",
    "        for i in range(self.g_steps):\n",
    "            # Train the generator\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal([batch_size, self.noise_length])\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake data using the generator\n",
    "                gen_samples = self.generator([random_latent_vectors, labels], training=True)\n",
    "                # Get the discriminator logits for fake data\n",
    "                results = self.discriminator([gen_samples, labels], training=True)\n",
    "                # Compute penalties for steep fft\n",
    "                difs1_ord1 = gen_samples[:, 1:, 2] - gen_samples[:, :-1, 2]\n",
    "                fft1_penalty = tf.reduce_mean(tf.abs(difs1_ord1))\n",
    "                difs10_ord1 = gen_samples[:, 1:, 3] - gen_samples[:, :-1, 3]\n",
    "                fft10_penalty = tf.abs(tf.reduce_mean(tf.abs((difs10_ord1[:, 1:] - difs10_ord1[:, :-1]))) - 1.3e-6)\n",
    "                # Calculate the generator loss\n",
    "                g_loss = -tf.math.log(results) + 100 * fft1_penalty + 10 * fft10_penalty\n",
    "\n",
    "            # Get the gradients w.r.t the generator loss\n",
    "            gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "            # Update the weights of the generator using the generator optimizer\n",
    "            self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "    \n",
    "    \n",
    "    def save_plots(self, nr_batch):\n",
    "        path = plots_dir + '/' + str(nr_batch)\n",
    "        os.mkdir(path)\n",
    "        nr_plots = 10\n",
    "        noise = np.random.normal(0, 1, (nr_plots, self.noise_length))\n",
    "        sampled_labels = labels[:nr_plots]\n",
    "        gen_samples = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        for i in range(nr_plots):\n",
    "            fig, subplots = plt.subplots(self.nr_features, 1)\n",
    "            fig.set_size_inches(40, 60)\n",
    "            for j in range(self.nr_features):\n",
    "                subplot = subplots[j]\n",
    "                subplot.plot(gen_samples[i, :, j])\n",
    "                [t.set_color('red') for t in subplot.yaxis.get_ticklines()]\n",
    "                [t.set_color('red') for t in subplot.yaxis.get_ticklabels()]\n",
    "                #subplots[j].axis('off')            \n",
    "            plt.savefig(path + '/%d.png' % (i))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size = 200, 32\n",
    "callback = cDCGANMonitor()\n",
    "cdcgan = cDCGAN()\n",
    "cdcgan.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cdcgan.fit(electrical_data, labels, batch_size=batch_size, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h1 = history.history\n",
    "plt.figure()\n",
    "plt.plot(history.history['g_loss'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['d_loss'])\n",
    "plt.show()\n",
    "\n",
    "np.savez_compressed(file_name + '.npz', **history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'samples_from_model'\n",
    "nr_samples = 5000\n",
    "batch_size = 50\n",
    "final_scores = [-9999] * nr_samples\n",
    "final_samples = np.zeros((nr_samples, 8760))\n",
    "sampled_labels = [[randint(0, 3), randint(3, 12), randint(12, 17), randint(17, 20), randint(20, 28)] for _ in range(nr_samples)]\n",
    "sampled_labels = np.array(sampled_labels)\n",
    "\n",
    "for k in range(0, 5000, batch_size):\n",
    "    batch_labels = sampled_labels[k:k + batch_size]\n",
    "    \n",
    "    for i in range(nr_trials):\n",
    "        noise = np.random.normal(0, 1, (batch_size, cdcgan.noise_length))\n",
    "        gen_samples = cdcgan.generator.predict([noise, batch_labels])\n",
    "        discriminator_scores = cdcgan.discriminator.predict([gen_samples, batch_labels])\n",
    "        for j, score in enumerate(discriminator_scores):\n",
    "            if score > final_scores[k + j]:\n",
    "                final_scores[k + j] = score\n",
    "                final_samples[k + j] = gen_samples[j, :, 0]\n",
    "    print('Finished for k =', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the spike at the end\n",
    "for electrical_value in final_samples:\n",
    "    electrical_value[-30:] = irfft(rfft(electrical_value[-30:])[:5], n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('../../data/processed/cdcgan_generated_data.npz', electrical_data=final_samples, labels=sampled_labels)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
